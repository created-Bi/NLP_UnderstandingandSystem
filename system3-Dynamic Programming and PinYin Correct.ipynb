{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.复习课上内容及代码。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.回答以下理论题目："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1 动态规划(DP)可以处理的问题有什么特点 ？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "    1. 重复子问题：在分解原问题为子问题，求解子问题的过程中，存在许多重复的计算；\n",
    "    2. 最优子结构：原问题的最优解包含其子问题的最优解，即原问题的最优解可以由子问题的最优解组合得到；\n",
    "    3. 无后效性：在当前子问题的决策过程中，不需要考虑前面的问题（上一个原问题）是如何解决的，即状态转移的过程中，当前状态只与前一个状态有关。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2 简单描述动态规划的几个步骤？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "    1. 根据题目写出状态转移方程，注意不同的状态转移到下一状态的情况；\n",
    "    2. 状态初始化，重要的是边界的初始化；\n",
    "    3. 根据状态转移方程，写出代码；\n",
    "    3. 根据题目找到最优解的情况，返回对应值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3 编辑距离算法的迭代公式是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "答：\n",
    "\n",
    "    1. 边界情况为，两个字符串中任一个长度为0，则函数直接返回另一个非0长度字符串的长度；\n",
    "    2. 状态转移方程：D[i][j] = min(D[i-1][j] + 1, D[i][j-1] + 1, D[i-1][j-1] + 1 if word1[i]==word2[j] else 0);\n",
    "    3. 由于D[i][j]表示word1前i个字符与word2前j个字符之间的编辑距离，所以最优解为D[len(word1)][len(word2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.实践题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 完成编辑距离解码函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编辑距离"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_parse_results = [] # 清空 parse 的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=2**10)\n",
    "def edit_distance(string1, string2):\n",
    "    \n",
    "    if len(string1) == 0: \n",
    "        cost = len(string2)\n",
    "        while len(string2) > 0:\n",
    "            solution[(\"\",string2)] = 'ADD {}'.format(string2[-1])\n",
    "            string2 = string2[:-1]\n",
    "        return cost #词1是空白 那么距离为词2的长度\n",
    "    if len(string2) == 0: \n",
    "        cost = len(string1)\n",
    "        while len(string2) > 0:\n",
    "            solution[(\"\",string2)] = 'DEL {}'.format(string1[-1])\n",
    "            string1 = string1[:-1]\n",
    "        return cost\n",
    "    \n",
    "    tail_s1 = string1[-1]\n",
    "    tail_s2 = string2[-1]\n",
    "    # (distance, operation)\n",
    "    candidates = [     # D[i-1,j]+1     删除操作 # ABCDECG=>ABCDEG=>ABCDE=>ABCD=>ABC=>AB=>A\n",
    "        (edit_distance(string1[:-1], string2) + 1, 'DEL {}'.format(tail_s1)),   \n",
    "        # string 1 delete tail\n",
    "                       #D[i,j-1]+1  插入操作 # \n",
    "        (edit_distance(string1, string2[:-1]) + 1, 'ADD {}'.format(tail_s2)),  \n",
    "        # string 1 add tail of string2\n",
    "    ]\n",
    "    \n",
    "    if tail_s1 == tail_s2:       #D[i-1,j-1]+0   D[i-1,j-1]=D[bc,bce] ==> D[i,j]=D[bcl,bcek]\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 0, '')\n",
    "    else:                       #D[i-1,j-1]+1\n",
    "        both_forward = (edit_distance(string1[:-1], string2[:-1]) + 1, 'SUB {} => {}'.format(tail_s1, tail_s2))\n",
    "\n",
    "    candidates.append(both_forward)  \n",
    "    \n",
    "    min_distance, operation = min(candidates, key=lambda x: x[0]) #min（D[i-1,j]+1, D[i,j-1]+1,D[i-1,j-1]+1/0）\n",
    "    \n",
    "    solution[(string1, string2)] = operation  #记录在对应的字符串对里该使用的操作\n",
    "\n",
    "    return min_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编辑距离最小的两个字符串，互相转换的操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    解析需要哪些操作的过程，相当于把状态转移的思想反过来，查看在word1与word2的状态时需要哪些操作\n",
    "'''\n",
    "def parse_results(word1, word2):\n",
    "    # 如果 word1 与 word2 不存在，返回\n",
    "    if not word1 and not word2: return list_parse_results\n",
    "    # 遇到相同的结尾字符，删除，无需操作\n",
    "    while word1 and word2 and word1[-1] == word2[-1]:\n",
    "        word1 = word1[:-1]\n",
    "        word2 = word2[:-1]\n",
    "    if not word1 and not word2: return list_parse_results\n",
    "    # 打印待处理的 word1 与 word2\n",
    "    print(\"{} ==> {}\".format(word1, word2), end=\"\")\n",
    "    temp = ' '.join([word1, '==>', word2, ': '])\n",
    "    # 得到能把word1变为word2的 操作\n",
    "    opera_letter = solution[(word1, word2)].split(\" \")\n",
    "    # 判断操作符，DEL：删除word1的最后一个词；ADD：在word1后面增加一个词；SUB：将word1的最后一个词替换\n",
    "    if opera_letter[0] == 'DEL': word1 = word1[:-1]\n",
    "    elif opera_letter[0] == 'ADD': word1 += opera_letter[1]\n",
    "    else: word1 = word1[:-1] + opera_letter[-1]\n",
    "        \n",
    "    temp += ' '.join(opera_letter)\n",
    "    # 将操作 添加到 列表中    \n",
    "    list_parse_results.append(temp)\n",
    "    # 打印操作\n",
    "    print(\", need to {}\".format(list_parse_results[-1]))\n",
    "    return parse_results(word1, word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word1 = 'negn'\n",
    "word2 = 'neng'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{('', 'neng'): 'ADD g', ('', 'nen'): 'ADD n', ('', 'ne'): 'ADD e', ('', 'n'): 'ADD n', ('n', 'n'): '', ('n', 'ne'): 'ADD e', ('n', 'nen'): 'ADD n', ('n', 'neng'): 'ADD g', ('ne', 'n'): 'DEL e', ('ne', 'ne'): '', ('ne', 'nen'): 'ADD n', ('ne', 'neng'): 'ADD g', ('neg', 'n'): 'DEL g', ('neg', 'ne'): 'DEL g', ('neg', 'nen'): 'SUB g => n', ('neg', 'neng'): '', ('negn', 'n'): 'DEL n', ('negn', 'ne'): 'DEL n', ('negn', 'nen'): '', ('negn', 'neng'): 'DEL n'}\n"
     ]
    }
   ],
   "source": [
    "print(edit_distance(word1,word2))\n",
    "print(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negn ==> neng, need to negn ==> neng : DEL n\n",
      "ne ==> nen, need to ne ==> nen : ADD n\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['negn ==> neng : DEL n', 'ne ==> nen : ADD n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_parse_results = []\n",
    "parse_results(word1,word2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 完成拼音自动纠错代码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何在不带空格的时候完成自动修整？--> 如何完成拼音的自动分割？   \n",
    "###### 提示：使用第一节课提到的语言模型!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语料预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体验版内测稳定版暂不受影响以确保工程师可以集中全部精力进行系统优化工作有人猜测这也是将精力主要用到MIUI9的研发之中MI\n"
     ]
    }
   ],
   "source": [
    "# 语料预处理1 —— 语料导入\n",
    "chinese_dataset = '../article_9k.txt'\n",
    "CHINESE_CHARATERS = open(chinese_dataset).read()\n",
    "print(CHINESE_CHARATERS[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ni hao ， zhong guo\n"
     ]
    }
   ],
   "source": [
    "# 语料预处理2 —— 文字转拼音\n",
    "import pinyin\n",
    "print(pinyin.get('你好，中国',format='strip',delimiter=' ')) # 举例\n",
    "def chinese_to_pinyin(character): # 定义文字转拼音的函数\n",
    "    return pinyin.get(character, format='strip', delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129433034\n"
     ]
    }
   ],
   "source": [
    "CHINESE_CHARATERS_COPYS = chinese_to_pinyin(CHINESE_CHARATERS) # 将文字语料 转为 拼音\n",
    "print(len(CHINESE_CHARATERS_COPYS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def tokens(text): # 将拼音全部变为小写 匹配所有拼音\n",
    "    \"List all the pinyin characters\"\n",
    "    return re.findall('[a-z]+',text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "PINYIN_COUNT = Counter(tokens(CHINESE_CHARATERS_COPYS))\n",
    "# ?PINYIN_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shi', 860634),\n",
       " ('de', 809887),\n",
       " ('n', 691114),\n",
       " ('yi', 682478),\n",
       " ('ji', 645276),\n",
       " ('guo', 430042),\n",
       " ('zhong', 409418),\n",
       " ('zhi', 398612),\n",
       " ('xin', 359619),\n",
       " ('li', 355441),\n",
       " ('zai', 334106),\n",
       " ('wei', 326301),\n",
       " ('hua', 304941),\n",
       " ('yu', 302949),\n",
       " ('she', 293312),\n",
       " ('he', 285689),\n",
       " ('bu', 281533),\n",
       " ('ri', 278379),\n",
       " ('jin', 278141),\n",
       " ('you', 277726)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINYIN_COUNT.most_common(20) # 存在 单字母拼音 如何去掉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_to_del = []\n",
    "for k,v in PINYIN_COUNT.items():\n",
    "    if len(k) == 1: need_to_del.append(k)\n",
    "for pinyin in need_to_del:\n",
    "    del PINYIN_COUNT[pinyin]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shi', 860634),\n",
       " ('de', 809887),\n",
       " ('yi', 682478),\n",
       " ('ji', 645276),\n",
       " ('guo', 430042),\n",
       " ('zhong', 409418),\n",
       " ('zhi', 398612),\n",
       " ('xin', 359619),\n",
       " ('li', 355441),\n",
       " ('zai', 334106),\n",
       " ('wei', 326301),\n",
       " ('hua', 304941),\n",
       " ('yu', 302949),\n",
       " ('she', 293312),\n",
       " ('he', 285689),\n",
       " ('bu', 281533),\n",
       " ('ri', 278379),\n",
       " ('jin', 278141),\n",
       " ('you', 277726),\n",
       " ('xian', 269047)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PINYIN_COUNT.most_common(20) # 不存在单字母拼音"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('yueri', 165274), ('xinhua', 151823), ('huashe', 145795), ('nn', 136525), ('nxin', 89783), ('zhongguo', 87864), ('waidai', 83330), ('nianyue', 77695), ('jizhe', 65213), ('nwai', 62999), ('erxian', 62428), ('daier', 61783), ('rin', 54162), ('zhaopian', 52347), ('nyue', 51736), ('shezhao', 50584), ('guoji', 47659), ('sheji', 45223), ('rizai', 44410), ('fazhan', 41026)]\n"
     ]
    }
   ],
   "source": [
    "TOKEN = tokens(CHINESE_CHARATERS_COPYS)\n",
    "\n",
    "TOKEN_BIGRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]\n",
    "words_count_bigram = Counter(TOKEN_BIGRAM)\n",
    "print(words_count_bigram.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps \n",
    "def time_consuming(func):  #告诉我们一个函数使用的时间\n",
    "    @wraps(func)\n",
    "    def wrapper(*args):\n",
    "        start = time.time()\n",
    "        t = func(*args)  #调用传入的func\n",
    "        end = time.time()\n",
    "        print('used time : {}'.format(end-start)) #func这个函数花费的时间\n",
    "        return t\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    'Return the pinyin in our data'\n",
    "    return [w for w in words if w in PINYIN_COUNT]\n",
    "\n",
    "def edits0(word):\n",
    "    'Return all strings that are zero edits away from word (i.e., just word itself).'\n",
    "    return [word]\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "\n",
    "def splits(word):\n",
    "    'Return a list of all possible (first, rest) pairs that comprise pinyin.'\n",
    "    return [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
    "\n",
    "def edits1(word):\n",
    "    'Return all strings that are one edit away from this pinyin.'\n",
    "    pairs = splits(word)   \n",
    "    # =====>>> 更改源码为 ''.join 避免重复赋值\n",
    "    deletes = [''.join([a,b[1:]]) for (a,b) in pairs if b] # input pinyin -删除操作 去掉b[0]\n",
    "    replaces = [''.join([a,c,b[1:]]) for (a,b) in pairs for c in alphabet if b] #替换  b[0]替换为c\n",
    "    inserts = [''.join([a,c,b]) for (a,b) in pairs for c in alphabet] #插入操作 在a和b之间插入字母\n",
    "    return list(set(deletes + replaces + inserts))\n",
    "\n",
    "def edits2(word):\n",
    "    'Return all strings that are two edits away from this pinyin.'\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)} #要计算编辑距离为2的词 可以通过计算与原词编辑距离为1的词的编辑距离为1的词\n",
    "\n",
    "@time_consuming\n",
    "def get_the_similar_word(word, words): # 这个函数 根据 对位字符或非对位字符的不同对应方式 给予每个编辑距离相近的更细致的评价\n",
    "    nums_count = [0 for _ in range(len(words))]\n",
    "    for i, waited_words in enumerate(words):\n",
    "        for j, w in enumerate(waited_words):\n",
    "            if w in word:\n",
    "                if j < len(word):\n",
    "                    if w == word[j]: nums_count[i] += len(word)-j+1\n",
    "                    else: nums_count[i] += (len(word)-j+1) / 2\n",
    "                else: nums_count[i] += 0.1\n",
    "            else: nums_count[i] -= 0.1\n",
    "    \n",
    "    return sorted(dict(zip(words, nums_count)).items(), key=lambda x:(x[1],x[0]), reverse=True)[0][0]\n",
    "\n",
    "def correct(word): #pinyin candidates piyin pingyin aogyin .... \n",
    "    'Find the most possible pinyin based on edit distance'\n",
    "    # Prefer edit distance 0, then 1, then 2; otherwist default to word itself\n",
    "    is_the_word_right = known(edits0(word)) # 编辑距离为0 那就是本身\n",
    "    if is_the_word_right: return word # 如果编辑距离（本身）在词表中，则直接返回\n",
    "    else: candidates = list(set(known(edits1(word))+ known(edits2(word))))  #计算所有与输入词编辑距离为0，1，2的词\n",
    "    #print(candidates)\n",
    "    \n",
    "    # 得到 所有可能的拼音 与其在拼音表中对应的 概率\n",
    "    prob_candidates = dict(zip(candidates, [PINYIN_COUNT.get(p,0) for p in candidates]))\n",
    "    #print(prob_candidates)\n",
    "    \n",
    "    # 按照 拼音表中的概率 排序\n",
    "    prob_candidates = sorted(prob_candidates.items(), key=lambda x:(x[1],x[0]), reverse=True)\n",
    "    #print(prob_candidates[:10])\n",
    "    \n",
    "    # 其它规则，我这里写的是： 先选出待选词中的前一半词，把这些词与 输入的word 进行匹配，输出匹配得最多的待选word\n",
    "    # 大概意思就是：negn 应该与 neng 更像，因为它们的长度更相似\n",
    "    return get_the_similar_word(word,[word for word, prob in prob_candidates[:len(prob_candidates)//2]]) #取出在所有candidate里在语料库里出现次数最多的词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used time : 3.4332275390625e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'neng'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('negn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used time : 0.00010347366333007812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'bi'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('bii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used time : 4.410743713378906e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'jia'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('jiaa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used time : 9.107589721679688e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'zhong'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('zhng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used time : 7.43865966796875e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'qi'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct('qii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    if word in PINYIN_COUNT: return PINYIN_COUNT(word) / len(PINYIN_COUNT)\n",
    "    else: return 1 / len(PINYIN_COUNT)\n",
    "\n",
    "def prob_2(word1, word2):  # p(w1,w2) = count(w1,2)/count(w1)\n",
    "    if word1 + word2 in words_count_bigram: return words_count_bigram[word1+word2] / PINYIN_COUNT[word1] + 1\n",
    "    else:\n",
    "        return 1 / len(words_count_bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    dp[i][j] ==> sentences 中 下标从i到j的拼音 存在的 概率\n",
    "'''\n",
    "@time_consuming\n",
    "def get_splited_PinYin(sentences):\n",
    "    n = len(sentences)\n",
    "    \n",
    "    dp = {} # 用于记录 所有可能的 字符串：（起始下标，终止下标） 与 其对应的概率\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            prob = PINYIN_COUNT.get(sentences[i:j+1],0)\n",
    "            if prob: dp[(i,j)] = prob\n",
    "    \n",
    "    indexes, probs = list(dp.keys())[::-1], list(dp.values())[::-1]\n",
    "    \n",
    "    print('Indexes: {}'.format(indexes))\n",
    "#     print('Probs: {}'.format(probs))\n",
    "    \n",
    "    res = []\n",
    "    \n",
    "    # 此函数 用于 找出下标跨度最大的 组合\n",
    "    def find_the_most_possible_one(start_ind, index):\n",
    "        if start_ind == 0: return\n",
    "        light, ind, max_distance = 0, -1, 0\n",
    "        for i, (left_ind, right_ind) in enumerate(indexes):\n",
    "            if right_ind+1 == start_ind:\n",
    "                if right_ind - left_ind + 1 > max_distance:\n",
    "                    ind = i\n",
    "                    max_distance = right_ind - left_ind + 1\n",
    "        if ind == -1: \n",
    "            res.append(sentences[indexes[index+1][0]:start_ind])\n",
    "            find_the_most_possible_one(indexes[index+1][0], index+1)\n",
    "        else: \n",
    "            res.append(sentences[indexes[ind][0]:indexes[ind][1]+1])\n",
    "            find_the_most_possible_one(indexes[ind][0], ind)\n",
    "\n",
    "    # 要从最后一个拼音开始找\n",
    "    find_the_most_possible_one(n, 0)\n",
    "    #print('After: {}'.format(res))\n",
    "\n",
    "    res = ' '.join(res[::-1])\n",
    "    print('Bofre the correction: {}'.format(res))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: [(14, 15), (12, 13), (10, 11), (8, 11), (8, 10), (8, 9), (6, 7), (2, 3), (0, 1)]\n",
      "Bofre the correction: wo negn xi huan ni ma\n",
      "used time : 0.0003962516784667969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'wo negn xi huan ni ma'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_splited_PinYin('wonegnxihuannima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_sequence_pinyin(text_pinyin):\n",
    "    return ' '.join(map(correct, get_splited_PinYin(text_pinyin).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: [(14, 15), (12, 13), (10, 11), (8, 11), (8, 10), (8, 9), (6, 7), (2, 3), (0, 1)]\n",
      "Bofre the correction: wo negn xi huan ni ma\n",
      "used time : 0.0006122589111328125\n",
      "used time : 3.695487976074219e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'wo neng xi huan ni ma'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sequence_pinyin('wonegnxihuannima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: [(22, 24), (22, 23), (20, 21), (16, 18), (16, 17), (12, 15), (12, 14), (12, 13), (9, 11), (9, 10), (8, 11), (8, 10), (8, 9), (7, 11), (7, 10), (7, 9), (4, 6), (4, 5), (2, 6), (2, 5), (2, 4), (2, 3), (0, 1)]\n",
      "Bofre the correction: wo xiang shang qing huax da xue\n",
      "used time : 0.0007498264312744141\n",
      "used time : 5.4836273193359375e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'wo xiang shang qing hua da xue'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sequence_pinyin('woxiangshangqinghuaxdaxue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexes: [(17, 18), (16, 18), (16, 17), (14, 15), (13, 15), (13, 14), (11, 12), (10, 12), (10, 11), (9, 12), (9, 11), (7, 8), (4, 6), (4, 5), (3, 6), (3, 5), (3, 4), (2, 6), (2, 5), (2, 4), (0, 1)]\n",
      "Bofre the correction: ni zhang de zhan hao kan\n",
      "used time : 0.0003974437713623047\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'ni zhang de zhan hao kan'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_sequence_pinyin('nizhangdezhanhaokan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
